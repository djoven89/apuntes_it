{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Apuntes IT personales relacionados con el estudio de distintas tecnolog\u00edas.</p> <p>M\u00e1s informaci\u00f3n sobre mi, o ejemplos de labs y proyectos completos aqu\u00ed.</p>"},{"location":"#aws","title":"AWS","text":"<ul> <li>Amazon Lambda</li> <li>Amazon API Gateway</li> <li>Amazon Auto Scaling Group</li> </ul>"},{"location":"aws/api-gateway/","title":"Amazon API Gateway","text":"<p>Es un servicio gestionado que hace sencillo para los desarrolladores publicar, mantener, monitorizar y securizar API.</p>"},{"location":"aws/api-gateway/#caracteristicas-principales","title":"Caracter\u00edsticas principales","text":"<ul> <li>Los tipo de APIs que podemos configurar son:<ul> <li>REST</li> <li>HTTP</li> <li>WebSocket</li> </ul> </li> <li>Las funcionalidades que ofrece el servicio son:<ul> <li>WebSocket (stateful).</li> <li>HTTP y REST (stateless)</li> <li>Autenticaci\u00f3n flexible con servicios como:<ul> <li>IAM</li> <li>Lambda authorized functions</li> <li>Amazon Cognito</li> </ul> </li> <li>Despliegues de tipo <code>canary</code> para Rest API.</li> </ul> </li> <li>El servicio puede integrar con:<ul> <li>Amazon CloudTrail</li> <li>Amazon CloudWatch</li> <li>AWS WAF</li> <li>AWS X-RAY</li> </ul> </li> <li>Es posible crear un <code>Mock integration</code> en una REST API.</li> <li>Para elegir entre una API REST o HTTP, tenemos este enlace donde nos explica las funcionalidades disponibles.</li> </ul>"},{"location":"aws/api-gateway/#terminologia-y-conceptos","title":"Terminolog\u00eda y conceptos","text":"<ul> <li><code>API method</code>: Combinaci\u00f3n de la ruta de un recurso con el verbo HTTP, por ejemplo:<ul> <li><code>POST /incomes</code></li> <li><code>GET /expenses</code></li> </ul> </li> <li><code>API stage</code>: Referencia l\u00f3gica a un ciclo de vida de la API. Es decir, el entorno (prod, staging, etc).</li> <li><code>Developer portal</code>: Aplicaci\u00f3n que permite a los clientes registrar, descubrir y suscribirse a la API, adem\u00e1s de gestionar sus API keys y visitar las m\u00e9tricas de uso.</li> </ul>"},{"location":"aws/api-gateway/#http-api","title":"HTTP API","text":"<ul> <li>Es una RESTful API.</li> <li>HTTP API est\u00e1 dise\u00f1ada con menos funcionalidades para tener un precio m\u00e1s bajo.</li> <li>Comparaci\u00f3n entre REST API y HTTP API aqu\u00ed.</li> <li>Funcionalidades principales:<ul> <li>Es posible enviar las request a AWS Lambda o a cualquier HTTP endpoint.</li> <li>Autenticaci\u00f3n con OpenID Connect y OAuth 2.0.</li> <li>CORS.</li> <li>Despliegues autom\u00e1ticos.</li> </ul> </li> <li>Para crear una API sencilla se necesitan configurar lo siguiente como m\u00ednimo:<ul> <li>Una ruta.</li> <li>Una integraci\u00f3n.</li> <li>Un stage.</li> <li>Un deployment.</li> </ul> </li> <li><code>Workflow de una request</code>:<ol> <li>El cliente env\u00eda una API request.</li> <li>API Gateway determina a que <code>stage</code> debe enruta la petici\u00f3n.<ul> <li>Si se hace match con un stage, se enruta a \u00e9ste la request, sino ir\u00e1 a <code>$default</code>, en caso de no existir, devuelve un <code>{\"message\":\"Not Found\"}</code> sin generar registros en CloudWatch Logs.</li> </ul> </li> <li>Una vez que el stage fue seleccionado, API Gateway selecciona la route.<ul> <li>La selecci\u00f3n se hace por el match m\u00e1s espec\u00edfico, usando las siguientes prioridades.<ol> <li>Match completo de route y method.</li> <li>Greedy path variable.</li> <li>$default.</li> </ol> </li> </ul> </li> <li>En caso de no haber match, se devuelve un <code>{\"message\":\"Not Found\"}</code> al cliente.</li> </ol> </li> <li><code>Routes</code><ul> <li>Enruta las API requests a un backend.</li> <li>Conta de dos partes:<ul> <li>HTTP method.</li> <li>Es posible usar <code>ANY</code> para hacer match de todos los m\u00e9todos no definidos en el resource.</li> <li>Podemos usar <code>$default</code> para actuar como catch-all para todas las requests que no hagan match en otros routes.</li> <li>Resource path.</li> <li>Es posible usar variables. <code>GET /pets/{petID}</code>.</li> <li>A greedy path variable catches all child resources of a route.<ul> <li>Debe a\u00f1adirse un <code>+</code> al final de la variable: <code>{proxy+}</code>.</li> <li>Debe estar siempre al final del path del resource.</li> </ul> </li> </ul> </li> <li>API Gateway decodifica los request parameters de la URL antes de pas\u00e1rselos a la integraci\u00f3n del backend.</li> <li>Por defecto, los query strings son enviados a la integraci\u00f3n del backend si est\u00e1n incluidos en la request.</li> </ul> </li> <li><code>Access control</code><ul> <li>Hay tres mecanismos para controlar y gestionar el acceso a la HTTP API:<ul> <li>Lambda authorizers</li> <li>Cuando un cliente hace una API requests, API Gateway invoca una funci\u00f3n Lambda. Dependiendo de la respuesta, el cliente podr\u00e1 o no acceder a la API.</li> <li>En caso de no usar la consola de AWS; habr\u00e1 que indicar la versi\u00f3n del payload soportada (1.0 \u00f3 2.0).</li> <li>Opcionalmente, se pueden establecer identity sources para la autorizaci\u00f3n de Lambda, de modo que si el cliente no los proporciona en la requests, API Gateway le devolver\u00e1 un 401 sin llegar siquiera a invocar la funci\u00f3n.<ul> <li>Headers.</li> <li>Query string.</li> <li>Context.</li> <li>Stage.</li> </ul> </li> <li>Es posible cachear la autorizaci\u00f3n.</li> </ul> </li> <li>JWT authorizers<ul> <li>Es posible usar JWT como parte de OIDC y OAuth 2.0 para restringir el acceso a la API.</li> <li>Cuando un cliente hace una API request, API Gateway valida el JWT enviado por el cliente. y determina si puede acceder a la API bas\u00e1ndose en la validaci\u00f3n del token y opcionalmente, en el scope del token.</li> <li>API Gateway enviar\u00e1 el claim en el token a la integraci\u00f3n de la ruta en cuesti\u00f3n.</li> </ul> </li> <li>Standard AWS IAM roles and policies<ul> <li>El cliente deber\u00e1 firmar la request con SigV4.</li> <li>Ser\u00e1 necesario que se disponga del permiso <code>execute-api</code> en la ruta para que API Gateway se invoque.</li> </ul> </li> </ul> </li> <li><code>Integrations</code><ul> <li>Permite conectar un route a recursos backend.</li> <li>Soporta:</li> <li>Lambda proxy<ul> <li>En caso de no usar la consola de AWS; habr\u00e1 que indicar la versi\u00f3n del payload soportada (1.0 \u00f3 2.0).</li> </ul> </li> <li>AWS service<ul> <li>Es posible integrar uno de estos servicios de AWS usando first-class integrations.</li> </ul> </li> <li>HTTP proxy integrations<ul> <li>Permite establecer un endpoint HTTP p\u00fablico.</li> <li>API Gateway env\u00eda toda la request y la respuesta.</li> </ul> </li> <li>Private integrations<ul> <li>Se integra con recursos privados de una VPC, que son:</li> <li>ELB</li> <li>ECS</li> <li>AWS Cloud Map service.</li> <li>Es necesario crear un VPC link para usar esta funcionalidad.</li> </ul> </li> </ul> </li> <li>Mediante parameter mapping podemos modificar la request ya sea por parte del clientes antes de enviarla a la integraci\u00f3n o la respuesta procedente de la integraci\u00f3n antes de envi\u00e1rsela al cliente.<ul> <li>Headers, Query strings y el path, son los par\u00e1metros que podemos modificar antes de enviar a la integraci\u00f3n.</li> <li>Headers y Status code son los par\u00e1metros que podemos modificar de la respuesta de la integraci\u00f3n antes de enviarla al cliente.</li> <li>Estas headers est\u00e1n reservadas, por lo que no podremos modificarlas.</li> </ul> </li> <li>Podemos definir nuestra HTTP API mediante la importaci\u00f3n de un archivo OpenAPI 3.0.</li> <li>Podemos migrar una API REST a una HTTP API mediante la exportaci\u00f3n de la API REST como OpenAPI 3.0.</li> <li>Por defecto, es posible crear una API a\u00fan con errores en la estructura del archivo. Es posible modificar este valor.</li> <li><code>Stage</code><ul> <li>Referencia l\u00f3gica a un ciclo de estado (dev, prod, v1, v2).</li> <li>Podemos usar stages o custom domain names para publicar la API.</li> <li>Es posible configurar integraciones y configuraciones distinta a cada stage.</li> <li>Podemos definir variables a un stage, las cuales actuar\u00edan como variables de entorno.<ul> <li>No deben contener informaci\u00f3n sensible como credenciales.</li> </ul> </li> <li>Si queremos usar un dominio custom, tendremos que usar API mapping para conectar la API stage con el dominio.<ul> <li>Es posible usar el mismo map para HTTP y REST APIs stages de un mismo dominio custom.</li> <li>Si queremos que los clientes s\u00f3lo puedan usar la API bajo el dominio custom, habr\u00e1 que deshabilitar el endpoint execute-api.</li> </ul> </li> <li>Para enviar informaci\u00f3n sensible a las integraciones, usar AWS Lambda authorized (usar el output de la funci\u00f3n Lambda para enviar la informaci\u00f3n sensible a las integraciones).</li> <li>En caso de necesitar establecer cookies con informaci\u00f3n sensible, es recomendable usar cookies con el prefijoo <code>__Host-</code> tal y como se comenta aqu\u00ed.</li> </ul> </li> <li>Podemos configurar la API con throttling para protegernos de recibir demasiadas requests.<ul> <li>API Gateway isa el algoritmo token bucket, se examina el rate y el burst of requests contra todas las APIs de una regi\u00f3n.</li> <li>Cuando las solicitudes superan los l\u00edmites, el cliente recibe un 429 Too Many Requests.</li> <li>Es posible configurarlo a nivel de API stage o a nivel de routes.</li> <li>A nivel de cuenta hay una quota que limita esta funcionalidad para protegernos de posibles ataques.</li> <li>Los valores son por segundo y son dos conceptos:<ul> <li>Burst limit</li> <li>Tama\u00f1o del bucket.</li> <li>N\u00famero de peticiones concurrentes por segundo.</li> <li>Rate limit</li> <li>N\u00famero de peticiones por segundo.</li> </ul> </li> </ul> </li> <li>Podemos configurar mutual TLS authentication, es decir, el cliente debe presentar un certificado X.509 para verificar el acceso a la API.<ul> <li>Se usa para IoT y aplicaciones business-to-business.</li> </ul> </li> <li>Podemos usar Amazon CloudWatch metrics y Logs para monitorizar la API.<ul> <li>Es posible que estos casos no sean registrados en Amazon CloudWatch.</li> <li>Por defecto, las m\u00e9tricas se env\u00edan cada minuto.</li> <li>Las m\u00e9tricas se almacenan durante 15 meses.</li> <li>Estas son las m\u00e9tricas disponibles.</li> <li>Es posible personalizar el access log con estas variables.</li> </ul> </li> </ul>"},{"location":"aws/api-gateway/#rest-api","title":"REST API","text":"<ul> <li>Colecci\u00f3n de recursos y m\u00e9todos que se integran con un backend de tipo:<ul> <li>HTTP endpoint.</li> <li>Lambda functions.</li> <li>Otros servicios de AWS.</li> </ul> </li> <li>El servicio interact\u00faa con los backend a trav\u00e9s de <code>integration requests</code> y <code>integration responses</code>.</li> <li>El frontend es encapsulado en <code>method requests</code> y <code>method responses</code>.</li> <li>Permite generar la documentaci\u00f3n de la API con <code>API Gateway extensions to OpenAPI</code>.</li> <li>El m\u00f3dulo que usa este tipo de API es request/response, es decir, el cliente env\u00eda una petici\u00f3n a un servicio y el servicio response de forma sincronizada.</li> <li>Construimos una REST API como una colecci\u00f3n de entidades programables llamadas <code>API Gateway Resources</code>.</li> <li>Cada entidad <code>Resource</code> tiene uno o m\u00e1s <code>Methods resources</code>.<ul> <li>Un <code>Method resource</code> es una petici\u00f3n entrante de un cliente que es expresada con par\u00e1metros y un body.</li> </ul> </li> <li>Para integrar un <code>method resource</code> con un backend endpoint (llamado <code>Integration endpoint</code>), creamos un <code>Integration resource</code>.<ul> <li>Permite enrutar la petici\u00f3n del cliente a un integration endpoint concreto.  -</li> </ul> </li> <li>Es posible transformar el par\u00e1metro o el body recibido para cumplir con los requisitos del backend.</li> <li>Para las respuestas, se crea un <code>Method response</code>, que representa la respuesta recibida del cliente.</li> <li>Para representar la respuesta del backend se crea un <code>Integration Response</code>.</li> <li>Es posible transformar los datos de la respuesta del backend antes de enviarlos al cliente.</li> <li>Para controlar quien puede consultar la API, podemos usar:<ul> <li>IAM.</li> <li>Lambda authorized.</li> <li>Amazon Cognito user pool.</li> </ul> </li> <li>Para medir y limitar el uso de la API, podemos usar <code>usage plans</code>.</li> <li>El <code>API endpoint type</code> (hostname), puede ser de varios tipos:</li> <li><code>Edge-optimized</code>         * Default.         * Enruta las peticiones al POP de CloudFront m\u00e1s cercano a la ubicaci\u00f3n geogr\u00e1fica del cliente.         * El nombre de los HTTP headers se establecen en may\u00fasculas.         * Los custom domain name se aplican a todas las regiones.<ul> <li><code>Regional</code><ul> <li>El uso es para clientes que est\u00e1n en la misma regi\u00f3n (EC2 como cliente y API gateway en la misma regi\u00f3n). Tambi\u00e9n cuando tenemos pocos clientes pero con gran demanda.</li> <li>Los custom domain name son espec\u00edficos de una regi\u00f3n.</li> <li>Es posible integrar los custom domain con Amazon Route 53 para habilitar la funcionalidad latency-based routing.</li> </ul> </li> <li><code>Private</code><ul> <li>S\u00f3lo puede accederse al API endpoint desde una VPC.</li> </ul> </li> </ul> </li> <li>Es posible cambiar el tipo de API endpoint, aqu\u00ed se explican las combinaciones.</li> <li>Al configurar el <code>API method</code> indicamos qu\u00e9 deber\u00eda o debe enviar un cliente en su respuesta al backend, adem\u00e1s, definimos las respuestas al cliente.<ul> <li>Es una petici\u00f3n HTTP, con su verbo HTTP, el path al recurso, headers y query strings.</li> <li>Deber\u00edamos configurar un payload cuando usamos <code>POST</code>, <code>PUT</code> o <code>PATCH</code>.</li> </ul> </li> <li>Como <code>Method request</code> (input de la request), es posible elegir entre par\u00e1metros o payload.</li> <li>Como <code>Method response</code> (output), determinamos el STATUS code, headers y el body antes de enviarlo al cliente.</li> <li>Si no tenemos un proxy integrado, deberemos configurar los <code>method responses</code>.<ul> <li>T\u00edpicamente, las respuestas son 2XX, 4XX o 5XX.</li> <li>Es com\u00fan establecer 500 como respuesta por defecto para excepciones.</li> </ul> </li> </ul> <p>https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-method-settings-method-request.html</p>"},{"location":"aws/api-gateway/#deployments","title":"Deployments","text":"<ul> <li>https://docs.aws.amazon.com/apigateway/latest/developerguide/rest-api-publish.html</li> </ul>"},{"location":"aws/api-gateway/#monitoring","title":"Monitoring","text":""},{"location":"aws/api-gateway/#websocket-apis","title":"WebSocket APIs","text":"<ul> <li>Tanto el cliente como el servidor pueden enviarse mensajes simult\u00e1neamente.</li> <li>El uso t\u00edpico de este tipo de APIs es:<ul> <li>Chats.</li> <li>Dashboards a tiempo real.</li> <li>Alertas y notificaciones a tiempo real.</li> </ul> </li> <li>El servicio permite:<ul> <li>Monitorizaci\u00f3n y limitaci\u00f3n de conexiones y mensajes</li> <li>Traceo de mensajes hac\u00eda los backends con AWS X-RAY.</li> <li>F\u00e1cil integraci\u00f3n con endpoints HTTP/HTTPS</li> </ul> </li> </ul>"},{"location":"aws/asg/","title":"Amazon EC2 Auto Scaling Group","text":""},{"location":"aws/asg/#caracteristicas-principales","title":"Caracter\u00edsticas principales","text":"<ul> <li>Colecci\u00f3n de instancias EC2 controladas por el servicio que permite gestionar el n\u00famero de EC2 en funci\u00f3n de la carga que tenga la aplicaci\u00f3n.</li> <li>Mediante pol\u00edticas podemos definir cu\u00e1ndo se escalar\u00e1n o desescalar\u00e1n instancias EC2.</li> <li>Cuando actualizamos el ASG como por ejemplo, la launch template, las instancias en ejecuci\u00f3n no obtendr\u00e1n los cambios.</li> <li>Es posible actualizar - reemplazar - una instancia usando instance refresh.</li> <li>Podemos actualizar manualmente una instancia sin necesidad de tener que eliminarla de varias maneras:<ul> <li>Poner la instancia en modo standby.</li> <li>Sacarla temporalmente del ASG y luego volver a unir.</li> </ul> </li> <li>Podemos hacer uso de rollbacks y checkpoints en caso de actualizar las instancias en ejecuci\u00f3n usando instance refresh.</li> <li>Podemos obtener el ID de la AMI mediante Amazon Systems Manager Parameter Store, aunque nos impedir\u00e1 el uso de otras funcionalidades como el rollback.</li> <li>Mediante Amazon Application Recovery Controller para mover las instancias de una regi\u00f3n con incidencias a otra.</li> <li>Es posible integrar el ASG con otros servicios como un ELB.</li> <li>Mediante instance maintenance policy es posible indicar c\u00f3mo se ir\u00e1n creando y reemplazando las instancias.</li> <li>Para controlar cuando una instancia est\u00e1 lista para gestionar peticiones, tenemos:<ul> <li>Health checks</li> <li>Instance warmup</li> </ul> </li> <li>Es posible crear hooks para que se ejecuten cuando una instancia est\u00e1 en un estado concreto.</li> <li>Podemos usar Spot instance e indicar un porcentaje de instancias on-demand y spot que deseamos tener en nuestro ASG.</li> <li>Es posible usar distintos tipos de instancia en un mismo ASG, pudiendo dejar al propio ASG quien seleccione un tipo u otro o configur\u00e1ndolo nosotros manualmente.</li> <li>En caso de que nuestras instancias tarden bastante en iniciar, podemos hacer uso de warm pools para reducir dr\u00e1sticamente esos tiempos.</li> </ul>"},{"location":"aws/asg/#general","title":"General","text":"<ul> <li>Esta funcionalidad permite tener un n\u00famero determinado de instancias EC2 para gestionar la carga de la aplicaci\u00f3n seg\u00fan la demanda que tenga.</li> <li>Auto Scaling groups es una colecci\u00f3n de instancias EC2.</li> <li>Se establece un n\u00famero m\u00ednimo y m\u00e1ximo de instancias EC2 a desplegar. Adem\u00e1s, es posible definir un <code>desired capacity</code> y ASG tratar\u00e1 de levantar las instancias.<ul> <li></li> <li>Imagen explicativa del concepto.</li> </ul> </li> <li>Si se especifican <code>scaling policies</code>, ASG levantar\u00e1 y terminar\u00e1 instancias seg\u00fan la demanda se incremente o reduzca.</li> <li>Podemos actualizar una instancia a modo de 'canary deployment' o incluso, ponerla en standby, lo que har\u00e1 que no est\u00e9 activa para los clientes, aunque podremos hacer troubleshooting en ella, hacer ajustes y luego, volver a ponerla en servicio.</li> <li>Podemos desplegar instancias on-demand y spot, incluso a la vez en el mismo ASG.</li> <li>Podemos usar distintos tipos de instancias y de opciones de compra en un mismo ASG.</li> <li>No es recomendable usar $Latest o $Default como valor a la hora de elegir la launch template, dado que habr\u00e1 funcionalidades como rollback o skip matching que no estar\u00e1n disponibles o que reemplazar\u00e1n las instancias m\u00e1s veces de las deseadas.</li> <li>La funcionalidad estas quotas aplicadas.</li> <li>Es posible desasociar una instancia del ASG y opcionalmente, volverla a incluir despu\u00e9s.<ul> <li>Se recomienda ponerlas en modo standby.</li> <li>En caso de no ajustar el desired capacity, ASG levantar\u00e1 otra instancia.</li> <li>S\u00f3lo se puede hacer cuando est\u00e1n en estado InService.</li> </ul> </li> <li>Hay ciertos requisitos a cumplir para unir una instancia auto-gestionada al ASG.<ul> <li>Debe estar RUNNING.</li> <li>Su AMI debe existir.</li> <li>Debe estar alojada en la misma regi\u00f3n.</li> <li>La AZ debe ser parte del ASG.</li> </ul> </li> <li>Podemos usar Amazon Application Recovery Controller para mover las instancias de una regi\u00f3n con incidencias a otra.</li> <li>Las estrategias de AZ para el ASG son:<ul> <li>Balanced best effort<ul> <li>ASG mantiene un n\u00famero igual de instancias entre las AZs.</li> <li>Si un launch falla en una AZ, ASG intentar\u00e1 crear la instancia en otra AZ.</li> </ul> </li> <li>Balanced only<ul> <li>Si un launch falla en una AZ, ASG seguir\u00e1 tratando de crear la instancia en la misma AZ.</li> </ul> </li> </ul> </li> <li>Respecto a una instancia terminada:<ul> <li>Si ten\u00eda una EIP asociada, est\u00e1 no ser\u00e1 eliminada del pool, por lo que si queremos usarla en otra instancia o eliminarla del pool, habr\u00e1 que usar un hook.</li> <li>Los vol\u00famenes EBS asociado ser\u00e1n eliminados si dicha opci\u00f3n est\u00e1 definida, sino simplemente estar\u00e1n disponibles pero sin usar.</li> </ul> </li> <li>Es posible establecer establecer un periodo de vida m\u00e1ximo de una instancia.<ul> <li>Nos permite ir reemplazando instancias peri\u00f3dicamente reduciendo la necesidad de usar instance refresh.</li> <li>No es recomendable establecer valores cortos, dado que puede verse afectado nuestro desired capacity y por ende la disponibilidad de la aplicaci\u00f3n.</li> <li>Podemos usar la opci\u00f3n Instance scale-in protection para garantizar que ciertas instancias no son eliminadas incluso si lleg\u00f3 el fin de la vida establecida.</li> <li>Es importante definir una instance maintenance policy para tener el mayor control posible sobre como se escala y desescala.</li> </ul> </li> </ul>"},{"location":"aws/asg/#funcionalidades","title":"Funcionalidades","text":"<ul> <li><code>Monitorizaci\u00f3n del estado de las instancias</code><ul> <li>Monitoriza la salud de cada instancia, en caso de que los health checks fallen, la eliminar\u00e1 y crear\u00e1 una nueva.</li> </ul> </li> <li><code>Custom health checks</code></li> <li><code>Balanceo de la capacidad entre m\u00faltiples AZs</code><ul> <li>ASG trata de mantener un mismo n\u00famero de instancias en cada AZ.</li> <li>En caso de que no haya un balance de instancias entre las AZs, ASG tratar\u00e1 de corregirlo de dos v\u00edas:<ul> <li>Availability zone balancing<ul> <li>Lanzar\u00e1 nuevas instancias antes de terminar las antiguas, de modo que no se reduzca el rendimiento.</li> <li>Es posible que se sobrepase la capacidad establecida hasta un 10%.</li> <li>Podemos definir <code>instance maintenance policies</code> para controlar nosotros mismos el rango entre otras cosas.</li> </ul> </li> <li>Capacity Rebalancing<ul> <li>S\u00f3lo es v\u00e1lido para instancias Spot.</li> <li>ASG tratar\u00e1 de crear nuevas instancias cuando se le reporte que una Spot instance tiene un elevado riesgo de interrupci\u00f3n.</li> </ul> </li> </ul> </li> </ul> </li> <li><code>M\u00faltiples tipos y 'purchase' en un mismo ASG</code><ul> <li>Es posible configurar instancias de tipo 'Spot' u 'On-Demand'.</li> <li>Podemos hacer uso de instancias reservadas o Saving plans en combinaci\u00f3n con On-Demand.</li> </ul> </li> <li><code>Remplazo autom\u00e1tico de Spot instances</code><ul> <li>Si se ven interrumpidas, ASG las remplazar\u00e1</li> <li>A trav\u00e9s del 'capacity rebalancing' monitoriza y reemplaza instancias de tipo Spot que tienen un porcentaje elevado de ser interrumpidas.</li> </ul> </li> <li><code>Load balancing</code><ul> <li>Se integra con el m\u00f3dulo de Elastic Load Balancing.</li> <li>ASG registra o desuscribe las instancias del ELB.</li> </ul> </li> <li><code>Scalability</code><ul> <li>A trav\u00e9s de pol\u00edticas es posible escalar o desescalar.</li> </ul> </li> <li><code>Instance refresh</code><ul> <li>Si el launch template sufre cambios, podemos usar ese mecanismo para actualizar la instancia.</li> <li>Se puede usar como un 'canary deployment', dado que permite modificar unas instancias y revisar el comportamiento antes de actualizar todo el scaling group.</li> </ul> </li> <li><code>Lifecycle hooks</code><ul> <li>Permite ejecutar acciones personalizadas ante eventos de creaci\u00f3n de instancias o terminaci\u00f3n.</li> </ul> </li> <li><code>Soporte para stateful workloads</code><ul> <li>Permite habilitar la protecci\u00f3n <code>scale-in</code> o definir pol\u00edticas custom de terminaci\u00f3n para instancias de larga duraci\u00f3n.</li> </ul> </li> </ul>"},{"location":"aws/asg/#lifecycle","title":"Lifecycle","text":"<ul> <li>Ante ambos eventos, podremos ejecutar hooks.</li> <li>Escalado<ul> <li>Se produce ante los eventos:<ul> <li>Cambio manual del tama\u00f1o del ASG.</li> <li>Pol\u00edtica de escalado.</li> <li>Escalado por programaci\u00f3n (hora).</li> </ul> </li> <li>El diagrama tras producirse el evento es el siguiente:     </li> <li>Las instancias permanecen en estado <code>InService</code> hasta que ocurre:<ul> <li>ASG decide terminar una instancia para reducir el tama\u00f1o.</li> <li>Establecemos la instancia en modo <code>Standby</code>.</li> <li>Detach de una instancia del ASG.</li> <li>Por fallos del health checks (se elimina y reemplaza).</li> </ul> </li> <li>Podemos asociar instancias al ASG, aunque \u00e9stas deber\u00e1n de cumplir ciertos criterios.</li> </ul> </li> <li>Desescalado<ul> <li>Se produce ante los eventos:<ul> <li>Cambio manual del tama\u00f1o del ASG.</li> <li>Pol\u00edtica de escalado.</li> <li>Escalado por programaci\u00f3n (hora).</li> </ul> </li> <li>ASG puede terminar una o m\u00e1s instancias.</li> <li>En cuanto el estado de la instancia pase a <code>Terminating</code>, ya no ser\u00e1 posible recuperarla.</li> <li>Se eliminar\u00e1 la vinculaci\u00f3n con el ELB en caso de estar integrado.</li> <li>El diagrama tras producirse el evento es el siguiente:     </li> <li>Podemos hacer un detach de la instancia, a partir de ese momento, la gestionaremos nosotros por separado del ASG.</li> </ul> </li> </ul>"},{"location":"aws/asg/#launch-template","title":"Launch template","text":"<ul> <li>Es el sustituto de launch configurations.</li> <li>Establece la configuraci\u00f3n que tendr\u00e1 la instancia EC2 al iniciarse.</li> <li>Cada actualizaci\u00f3n de la plantilla ser\u00e1 una versi\u00f3n inmutable, lo que nos permitir\u00e1 usar una versi\u00f3n concreta en el ASG.</li> <li>Todos los par\u00e1metros son opcionales, no obstante, un ASG no puede usarse sin una AMI, por lo que realmente, este ser\u00eda el par\u00e1metro 'obligatorio' a definir.</li> <li>No se validan todos los par\u00e1metros, por lo que si hay alg\u00fan tipo de incompatibilidad o error en las opciones definidas, la instancia no ser\u00e1 iniciada.</li> <li>Es posible usar Amazon Systems Manager Parameter Store para obtener la AMI ID.<ul> <li>Tiene una serie de limitaciones importantes, las cuales se indican aqu\u00ed.</li> </ul> </li> <li>Si la versi\u00f3n de la plantilla en el ASG, las nuevas instancias har\u00e1 uso de la configuraci\u00f3n establecida, no obstante, para las existentes tendremos las siguientes opciones:</li> <li>Usar instance refresh.</li> <li>Terminaci\u00f3n manual de la instancia.</li> <li>Esperar a que ASG la termine por alg\u00fan evento.</li> </ul>"},{"location":"aws/asg/#health-checks","title":"Health checks","text":"<ul> <li>ASG recibe notificaciones del estado de una instancia de una o m\u00e1s fuentes:<ul> <li>Amazon EC2<ul> <li>Default.</li> <li>Comprueba:<ol> <li>Los checks propios de la propia instancia EC2: instance status check y system status check.</li> <li>Si la instancia tiene un estado distinto a running.</li> </ol> </li> <li>Si la instancia tiene asociado un Schedule event, ASG reemplaza la instancia aunque no la termina hasta que la fecha del evento termina.</li> </ul> </li> <li>Amazon EBS<ul> <li>El volumen es alcanzable y pasa los checks I/O.</li> </ul> </li> <li>Custom health checks<ul> <li>Comprueba los checks definidos por nosotros mismos.</li> <li>Se configura un script en la instancia que dependiendo de las condiciones especificadas, se notificar\u00e1 a la API de ASG si la instancia est\u00e1 healthy o no.</li> <li>Aqu\u00ed un ejemplo de configuraci\u00f3n usando un hook.</li> </ul> </li> <li>ELB<ul> <li>Comprueba el reporte del health check definido en el propio ELB para la instancia.</li> </ul> </li> <li>VPC Lattice</li> </ul> </li> <li>Cuando una instancia em <code>InService</code> est\u00e1 en modo unhealthy, se reemplaza por una nueva para mantener en n\u00famero de desired capacity del grupo.</li> <li>Es posible pausar temporalmente el proceso de autoscalado y poder debugear una incidencia evitando que se vayan creando y eliminando las instancias.<ul> <li>Los tipos de proceso que se pueden suspender est\u00e1n definidos aqu\u00ed y aqu\u00ed se describen como afecta al resto.</li> </ul> </li> <li>Es posible establecer un m\u00ednimo de segundos (grace period) para instancias nuevas antes de eliminarlas cuando han sido marcadas como unhealthy.<ul> <li>Esto es \u00fatil en caso de que la instancia todav\u00eda est\u00e9 siendo iniciada y requiera de m\u00e1s tiempo para cumplir con los requisitos de los checks.</li> <li>Si se usan hooks para el despliegue de nuevas instancias, podemos dejar el valor a 0 dado que ASG usa otros m\u00e9todos para garantizar que la instancia est\u00e1 iniciada.</li> <li>Esta valor se aplica a:<ul> <li>Lanzamiento de nuevas instancias.</li> <li>Instancias reactivadas tras estar en standby.</li> <li>Instancias asociadas manualmente.</li> </ul> </li> <li>Es altamente recomendable establacer un warnup a la instancia.</li> <li>Si se detecta que la instancia no est\u00e1 en estado running ser\u00e1 marcada para su reemplazo.</li> </ul> </li> </ul>"},{"location":"aws/asg/#instance-maintenance","title":"Instance maintenance","text":"<ul> <li>Es posible configurar pol\u00edticas para que el ASG cumpla con ciertos requisitos ante eventos que causen un reemplazo de una instancia, los cuales son:<ul> <li>Instance refresh.</li> <li>Health checks failure</li> <li>Max instance lifetime.</li> <li>Rebalancing.</li> </ul> </li> <li>Un ejemplo ser\u00eda que cuando haya una instancia unhealthy, se levante una nueva y hasta que no sea operativa, no se elimine la otra.</li> <li>Tambi\u00e9n permite minimizar una posible p\u00e9rdida de servicio cuando varias instancias se est\u00e1n reemplazando a la vez.</li> <li>Hay 3 pol\u00edticas disponibles:<ul> <li>Launch before terminating:<ul> <li>Lanza una nueva instancia y cuando est\u00e1 operativa, elimina la anterior.</li> <li>HA sobre costes.</li> </ul> </li> <li>Terminate and launch:<ul> <li>Termine y lanza una instancia a la vez.</li> <li>Costes sobre HA.</li> </ul> </li> <li>Custom:<ul> <li>Permite definir un m\u00ednimo y m\u00e1ximo de capacidad cuando se produce un evento de reemplazo.</li> </ul> </li> </ul> </li> <li>Por defecto, la funcionalidad est\u00e1 deshabilitada, usando estas pol\u00edticas.</li> <li>Si se usa un warm pool, los min y max healthy percentages son aplicados separados al warm pool.</li> <li>No es necesario establecer el porcentaje para min y max de healthy en la funcionalidad instance refresh salvo que queramos sobreescribirlos.</li> </ul>"},{"location":"aws/asg/#instance-standby","title":"Instance standby","text":"<ul> <li>Podemos modificar el estado de una instancia de InService a Standby para poder actualizarla o debugearla, y despu\u00e9s, volver a ponerla en servicio.</li> <li>La instancia seguir\u00e1 siendo parte del ASG pero no estar\u00e1 activa, ni siquiera para el ELB.</li> <li>Podemos indicar al ASG si queremos que mientras est\u00e9 en este modo, se cree una nueva instancia o se reduzca el desired capacity.</li> <li>Al volver a incluir la instancia, el desired capacity se incrementa.</li> <li>Habr\u00e1 que tener en cuenta la capacidad m\u00ednima y m\u00e1xima del ASG.</li> <li>La instancia sigue generando costes a\u00fan en este estado.</li> <li>No se realizan health checks mientras est\u00e9 en este estado.</li> </ul>"},{"location":"aws/asg/#instance-refresh","title":"Instance refresh","text":"<ul> <li>Permite actualizar una instancia del ASG.</li> <li>Se usa cuando hemos actualizado el ASG, como por ejemplo, el launch template y queremos que las instancias existentes obtengan dichos cambios.</li> <li>Este proceso elimina la instancia y crea otra en su lugar.</li> <li>Podremos seleccionar el porcentaje de instancias a reemplazar simult\u00e1neamente.<ul> <li>Si ya tenemos una instance maintenance policy no ser\u00e1 necesario usar estos porcentajes salvo que queramos sobreescribirlos.</li> </ul> </li> <li>Salvo que tengamos la funcionalidad warmup, no es necesario establecer el instance warmup period.</li> <li>Antes de activar la funcionalidad, podemos establecer algunas preferencias que afectar\u00e1n al proceso, las cuales se explican aqu\u00ed.</li> <li>Habr\u00e1 que tener en consideraci\u00f3n si tenemos o vamos a integrar en la launch template a desplegar mixed instance policy, dado que es posible que se reemplacen las instancias Spot por On-demand o viceversa, dependiendo de si eliminamos esta funcionalidad o la a\u00f1adimos.</li> <li>Mediante checkpoints podemos definir el porcentaje de instancias que ser\u00e1n reemplazadas a la vez en 'lotes', habiendo una pausa entre 'lotes', de modo que podamos verificar que todo va seg\u00fan lo planeado.<ul> <li>Si se cancela o se produce un fallo antes de llegar al \u00faltimo checkpoint, no se hace un rollback de las instancias ya reemplazadas.</li> <li>Una vez terminado el proceso completo, hasta que las instancias no hayan terminado el 'warm up', no se actualiza el porcentaje.</li> </ul> </li> <li>El lifecycle es:<ul> <li></li> </ul> </li> <li>Los estados por los que pasa cuando se inicia el proceso son:</li> <li>Pending</li> <li>InProgress</li> <li>Successful, Failed, Cancelled, RollbackSuccessful, or RollbackFailed.</li> <li>La descripci\u00f3n de cada estado se detalla aqu\u00ed.</li> <li>Es posible cancelar el proceso mientras est\u00e9 en el estado *InProgress.<ul> <li>No hace un rollback de las instancias ya reemplazadas.</li> </ul> </li> <li>Es posible hacer un rollback si el proceso est\u00e1 en el estado *InProgress.<ul> <li>Se reemplazan las instancias ya reemplazadas usando la configuraci\u00f3n que ten\u00eda.</li> <li>Hay dos maneras de hacer este proceso:<ul> <li>Manual<ul> <li>Nosotros iniciamos este proceso manualmente.</li> </ul> </li> <li>Auto<ul> <li>ASG realiza el proceso si el instance refresh fall\u00f3 o una alerta cambi\u00f3 al estado ALARM.</li> </ul> </li> </ul> </li> <li>No es posible usar esta funcionalidad cuando:<ul> <li>Cuando se hizo el instance refresh no se configur\u00f3 el desired configuration.</li> <li>La versi\u00f3n del launch template es $Latest o $Default.</li> <li>Si se usa Parameter Store.</li> </ul> </li> </ul> </li> </ul>"},{"location":"aws/asg/#hooks","title":"Hooks","text":"<ul> <li>Permite dise\u00f1ar l\u00f3gica ante los siguientes eventos:<ul> <li>Launching</li> <li>Terminating</li> </ul> </li> <li>Por defecto, se dispone de 1 hora para que el hook termine y la instancia transite al siguiente estado.</li> <li>El ciclo de vida de ASG es:     </li> <li>El resultado del puede ser: continue o abandon.<ul> <li>Abandon causar\u00e1 que se reemplace la instancia.</li> </ul> </li> <li>En caso de no publica el resultado del hook, el estado se especificar\u00e1 por el valor por defecto establecido en el ASG.</li> <li>Hay un rate limit que verifica si los hooks de creaci\u00f3n est\u00e1n fallando constantemente.</li> <li>Hay ciertas opciones s\u00f3lo disponibles v\u00eda CLI y SDK cuando se crea o actualiza un hook.</li> <li>Es posible usar distintos roles o notification targets usando eventos PutLifecycleHook por separado.</li> <li>ASG y Warm pool tienen sus propios hooks.</li> <li> <p>Funcionamiento de los hooks:</p> <ul> <li>A trav\u00e9s del user data se realizan los hooks de tipo 'launching'.</li> <li>Es necesario hacer una llamada a CompleteLifecycleAction para notificar al ASG que el lifecycle se ha completado.</li> <li>Podemos a\u00f1adir hasta un total de 50 hooks en un ASG.</li> <li>Para a\u00f1adir un hook desde la consola, tendremos que hacerlo con el ASG ya creado, mientras que v\u00eda CLI o SDK podremos hacerlo mientras creamos el ASG.</li> <li>Podemos configurar un notification target que sea: SNS o SQS durante la creaci\u00f3n del propio hook v\u00eda CLI o SDK.</li> <li>Si quieres usar servicios de AWS como Lambda para nuestros custom actions, tenemos que crear una regla en Amazon EventBridge, teniendo a la funci\u00f3n Lambda como target.</li> <li>Si queremos ejecutar acciones en determinados lifecycle, tenemos que usar la metadata de la instancia.</li> </ul> <pre><code>TOKEN=`curl -X PUT \"http://169.254.169.254/latest/api/token\" -H \"X-aws-ec2-metadata-token-ttl-seconds: 21600\"` \\\n&amp;&amp; curl -H \"X-aws-ec2-metadata-token: $TOKEN\" -v http://169.254.169.254/latest/meta-data/autoscaling/target-lifecycle-state\n</code></pre> <ul> <li>Es posible extender el tiempo del heartbeat usando record-lifecycle-action-heartbeat desde la CLI.</li> <li>Lo que hace es reiniciar el contador, por lo que si nuestro valor era 60 minutos y hemos consumido 30, se convertir\u00e1n en 90.</li> </ul> </li> </ul>"},{"location":"aws/asg/#asg-con-mixed-instances-group","title":"ASG con Mixed instances group","text":"<ul> <li>Hay dos opciones:<ul> <li>Attribute-based instance type-selection<ul> <li>En lugar de tener que seleccionar nosotros manualmente el tipo de instancias que pueden desplegarse, le dejamos que sea el propio ASG quien las seleccione.</li> <li>La selecci\u00f3n la hace en funci\u00f3n de los estos atributos especificados en el ASG. Algunos ejemplos:<ul> <li>vCPU: M\u00ednimo y m\u00e1ximo de vCPU por instancia.</li> <li>RAM: M\u00ednimo y m\u00e1ximo de RAM por instancia.</li> </ul> </li> <li>Es posible establecer el desired capacity al n\u00famero de vCPU o RAM, lo que lo hace una alternativa al instance weights.</li> <li>Es posible habilitar un <code>price protection</code> para evitar que ASG levante instancias muy caras.<ul> <li>Est\u00e1 habilitado por defecto.</li> <li>La protecci\u00f3n para on-demand y Spot se deben configurar por separado.</li> </ul> </li> <li>Es posible usar <code>performance protection</code> para que ASG tenga una referencia del tipo de instancia que tenga que elegir, es decir, que deber\u00eda ser similar o mejor a nivel de rendimiento.<ul> <li>S\u00f3lo soporte por el momento rendimiento a nivel de CPU.</li> </ul> </li> <li>Es posible hacer una preview del tipo de instancias que har\u00edan match con los atributos y funcionalidades establecidas.</li> </ul> </li> <li>Manual instance type-selection<ul> <li>Somos nosotros quien elegimos los tipos de instancias que podr\u00e1 desplegar el ASG.</li> </ul> </li> </ul> </li> <li>Permite que el ASG pueda desplegar otro tipo de instancias en caso de que en las AZs en cuesti\u00f3n no haya suficiente instance capacity (Spot instances).<ul> <li>Lo que har\u00eda el ASG ser\u00eda levantar instancias on-demand para satisfacer los requisitos de la aplicaci\u00f3n.</li> <li>Es recomendable tener al menos 10 tipos distintos y no centrarse \u00fanicamente en instancias de \u00faltima generaci\u00f3n (Spot instances).</li> </ul> </li> <li>Por defecto usa on-demand instances, aunque es posible definir el porcentaje de instancias on-demand y spot.</li> <li>Es posible configurar distintos launch templates, aunque s\u00f3lo es posible hacerlo v\u00eda CLI o SDK.</li> <li>Aqu\u00ed se explican las distintas estrategias para los dos tipos (on-demand y spot).</li> <li><code>Instance weights</code><ul> <li>Es posible indicar un valor/peso para cada tipo de instancia definida.</li> <li>La diferencia de peso entre el tipo de instancias no deber\u00eda extremo.</li> <li>Es preferible usar desired capacity in units y no instancias.</li> <li>Deberemos de configurar nuestros desired capacity para que sean 2 o 3 veces m\u00e1s grandes que nuestra mayor peso.</li> </ul> </li> <li><code>Capacity Rebalancing</code><ul> <li>ASG tratar\u00e1 de mantener una disponibilidad en nuestro workload creando nuevas instancias de tipo Spot antes de que las existentes sean interrumpidas.</li> <li>ASG monitoriza monitoriza y responde ante cambios (rebalance recommendation) que puedan afectar a la disponibilidad de las instancias de tipo Spot.</li> <li>En caso de no usar esta funcionalidad, ASG reemplazar\u00e1 las instancias una vez han sido interrumpidas, afectando a la capacidad del servicio.</li> <li>Si se recibe un rebalance recommendation, ASG lanzar\u00e1 una nueva instancia si la nueva instancia provee de la misma o mejor disponibilidad que la actual.</li> </ul> </li> </ul>"},{"location":"aws/asg/#spot-instances","title":"Spot instances","text":"<ul> <li>TODO:<ul> <li>https://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-template-spot-instances.html</li> <li>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-best-practices.html</li> </ul> </li> <li>Es altamente recomendable no usar el precio m\u00e1ximo, dado que es posible que no se puedan desplegar instancias.</li> <li>Si no establecemos un m\u00e1ximo, el valor por defecto es el coste de On-demand.</li> <li>Es recomendable crear acciones custom cuando la instancia ha recibido la notificaci\u00f3n de interrupci\u00f3n.<ul> <li>Crear un hook que permita apagar la aplicaci\u00f3n de forma exitosa y no forzosa.</li> <li>Se podr\u00eda crear un script de apagado que obtenga el estado de la instancia para que por ejemplo; subir logs a S3, desuscribirse de alg\u00fan servicio, etc.</li> <li>Es posible usar Amazon EventBridge para realizar las fuera de la instancia.</li> </ul> </li> <li>Es cr\u00edtico dise\u00f1as las acciones custom para que terminen antes de 2 minutos, que es el tiempo que tarda Amazon en notificar la interrupci\u00f3n de la instancia.<ul> <li>Hay veces que la interrupci\u00f3n se produce en el mismo momento que se recibe la notificaci\u00f3n.</li> </ul> </li> <li>Cuando menor sea el precio establecido, mayor es la posibilidad de interrupci\u00f3n.</li> <li>Recomendable usar la estrategia <code>price-capacity-optimized</code> en lugar de <code>lowest-price</code> para Spot instances.</li> <li>Es posible configurar integrar fleets de EC2 en el ASG.</li> </ul>"},{"location":"aws/asg/#instance-warmup","title":"Instance warmup","text":"<ul> <li>Proporciona m\u00e1s tiempo a una instancia en estado InService para iniciar antes de que se empiecen a registrar los datos de uso en CloudWatch metrics.</li> <li>No est\u00e1 habilitado por defecto.</li> <li>Es altamente recomendable configurar esta opci\u00f3n para evitar que las pol\u00edticas de escalado no se disparen innecesariamente.</li> <li>Es especialmente recomendable si tenemos pol\u00edticas de escalado del tipo: target tracking y step scaling</li> <li>Al habilitar esta configuraci\u00f3n, no tenemos que establecer el valor en:<ul> <li>Instance refresh.</li> <li>Target tracking scaling.</li> <li>Step scaling.</li> </ul> </li> </ul>"},{"location":"aws/asg/#warm-pool","title":"Warm pool","text":"<ul> <li>Permite reducir la latencia de aplicaciones que tienen un periodo de inicio muy extenso.</li> <li>Pool de instancias pre-iniciadas que usa ASG cuando tiene que levantar nuevas instancias.</li> <li>Las instancias en este pool pueden estar en tres estados:<ul> <li>Running</li> <li>Stopped<ul> <li>S\u00f3lo le paga por la EIP y el EBS.</li> <li>El health check lo obtiene del volumen EBS.</li> </ul> </li> <li>Hibernated<ul> <li>S\u00f3lo se paga por la EIP, EBS y el almacenamiento de la RAM.</li> </ul> </li> </ul> </li> <li>Hay estados adicionales para el pool:   </li> <li>Es posible configurar hooks.</li> <li>Cuando una instancia es eliminada, se crea una nueva en el pool.</li> <li>Es posible mover una instancia que iba a ser eliminada al pool de nuevo mediante una reuse policy.<ul> <li>S\u00f3lo es posible configurar esta opci\u00f3n v\u00eda CI o SDK.</li> </ul> </li> <li>En caso de haber aplicado cambios en el launch template a nuestro pool existente, podremos hacer un refresh de la instancia.</li> <li>No podemos usar esta funcionalidad con:<ul> <li>ASG que tengan distintos tipos de instancias.</li> <li>Si el launch template tiene Spot instances.</li> <li>Si se usa Parameter Store para obtener el ID de la AMI.</li> </ul> </li> <li>Las instancias en este pool tienen sus propios hooks independientes a los nuestros.</li> </ul>"},{"location":"aws/asg/#integracion-elb","title":"Integraci\u00f3n ELB","text":"<ul> <li>Se asocia el ELB al ASG.</li> <li>No es necesario registrar instancias EC2, sino que ser\u00e1 el propio ASG quien cree o termine las instancias seg\u00fan la demanda.</li> <li>Es posible crear una pol\u00edtica de escalado basado en las m\u00e9tricas del ELB.</li> <li>Es posible integrar los health checks del ELB al ASG para determinar y reemplazar instancias unhealthy.<ul> <li>Por defecto, no se consideran los health checks del ELB.</li> </ul> </li> <li>El target group del ELB debe ser de tipo <code>instance</code>.</li> <li>Si tenemos bootstrapping scripts que requiere cierto tiempo en ejecutarse, opcionalmente podemos crear un lifecycle hook al ASG de modo que haya un delay a la hora de registrar la instancia al ELB.</li> </ul>"},{"location":"aws/asg/#politicas-de-escalado","title":"Pol\u00edticas de escalado","text":"<ul> <li>Por defecto no hay ninguna pol\u00edtica de escalado definida.</li> <li>Es recomendable usar pol\u00edticas step scaling o target tracking en lugar de simple scaling para el tipo de escalado scale based on demand.</li> <li>El tipo de pol\u00edtica recomendable es target tracking el tipo de escalado scale based on demand.</li> <li>Si las m\u00e9tricas de la aplicaci\u00f3n se incrementa o reducen proporcionalmente, es recomendable usar target tracking.</li> <li>Es posible deshabilitar temporalmente una pol\u00edtica de escalado.</li> <li>Al eliminar una pol\u00edtica de escalado es posible que se requiera eliminar la alarma de CloudWatch manualmente.<ul> <li>El tipo target tracking las elimina autom\u00e1ticamente.</li> </ul> </li> <li>ASG provee de 5 maneras de escalar.</li> </ul>"},{"location":"aws/asg/#maintain-a-fixed-number-of-instances","title":"Maintain a fixed number of instances","text":"<ul> <li>Se define el n\u00famero de instancias que siempre deber\u00e1 de haber activas.</li> <li>Este es el m\u00e9todo por defecto, es decir, ausencia de pol\u00edticas.</li> <li>Se usan health checks para detectar su estado.</li> <li>Si el estado es unhealthy, terminar\u00e1 la instancia y lanzar\u00e1 una nueva.</li> </ul>"},{"location":"aws/asg/#scale-manually","title":"Scale manually","text":"<ul> <li>Es la opci\u00f3n m\u00e1s b\u00e1sica.</li> <li>Se define manualmente el valor del desired capacity del ASG o se terminan las instancias.</li> <li>Amazon se encargar\u00e1 de levantar o terminar las instancias.</li> <li>Es posible desescalar manualmente el ASG eliminando una instancia concreta desde la CLI.</li> </ul>"},{"location":"aws/asg/#scale-based-on-schedule","title":"Scale based on schedule","text":"<ul> <li>Se realiza el escalado basado en una programaci\u00f3n del d\u00eda y la hora, para que sea recurrente o espor\u00e1dico - inicio y fin -.</li> <li>\u00datil en casu\u00edsticas con carga predecible.</li> <li>Es posible combinar este tipo de pol\u00edtica con el resto de pol\u00edticas de escalado.</li> </ul>"},{"location":"aws/asg/#scale-based-on-demand-dynamic","title":"Scale based on demand (dynamic)","text":"<ul> <li>Es la opci\u00f3n m\u00e1s popular y avanzada.</li> <li>Mediante pol\u00edticas de escalado personalizadas podemos definir los par\u00e1metros de control el escalado.</li> <li>Un ejemplo t\u00edpico es escalar una instancia cuando la CPU est\u00e1 por encima del 70%.</li> <li>Las acciones a realizar por la pol\u00edtica se disparan cuando una alerta est\u00e1 en estado <code>ALARM</code>.</li> <li>Las m\u00e9tricas que se usan son las que tienen una aggregation de todas las instancias que conforman el ASG.</li> <li>Nunca se escalar\u00e1 por encima del m\u00e1ximo definido a excepci\u00f3n de si se usa instance weights.</li> <li>El capacity a escalar se mide en una de las siguientes maneras:<ol> <li>Desired capacity.</li> <li>Capacity units (instance weights).</li> </ol> </li> <li>En caso de que varias pol\u00edticas activen el escalado a la vez, Auto Scaling eligir\u00e1 la pol\u00edtica que proporcione mayor capacidad de escalado ascendente (out) o descendiente (in).</li> <li>Es posible definir m\u00faltiples pol\u00edticas de tipo target tracking y step, adem\u00e1s de schedule.</li> <li>Hay varios tipos de pol\u00edticas que podemos definir:<ul> <li>Target tracking scaling<ul> <li>Opci\u00f3n recomendada.</li> <li>Escala en base al valor de una m\u00e9trica de CloudWatch.</li> <li>Aumenta o disminuye la capacidad actual del grupo en funci\u00f3n en un valor de destino especificado en una determinada m\u00e9trica.</li> <li>Se recomienda cuando se aumente o disminuya en proporci\u00f3n al n\u00famero de instancias de un grupo.</li> <li>Cuando la m\u00e9trica est\u00e9 por encima del valor de destino, se realizar\u00e1 un escalado ascendente, pero no al rev\u00e9s.</li> <li>Se pueden tener m\u00faltiples pol\u00edticas siempre y cuando usen m\u00e9tricas diferentes.</li> <li>En caso de haber m\u00faltiples pol\u00edticas:</li> <li>El escalado ascendente suceder\u00e1 si cualquier de ellas est\u00e1 lista para escalar.</li> <li>El escalado descendente requiere que todas las pol\u00edticas est\u00e9n listas para desescalar.</li> <li>Es posible usar otro tipo de pol\u00edticas para el escalado descendentes.</li> <li>No se debe modificar ni eliminar las alarmas de CloudWatch configuradas para este tipo de pol\u00edticas.</li> <li>Hay 4 m\u00e9tricas disponibles por defecto (1 de CPU, 2 de Network y 1 de ALB) para este tipo de pol\u00edticas.</li> <li>Se requiere de CLI o SDK para crear pol\u00edticas con m\u00e9tricas personalizadas.</li> <li>Durante el escalado ascendente, la instancia en curso no cuenta como capacidad actual.</li> <li>Durante el escalado descendente, la instancia que est\u00e1 siendo terminada cuenta como capacidad actual.</li> <li>No es posible hacer un escalado descendente mientras hay otra actividad de escalado ascendente en curso.</li> <li>Si la m\u00e1etrica tiene como estado <code>INSUFFICIENT_DATA</code>, ASG no escalar\u00e1 hasta que la m\u00e9tricas reciba datos.</li> <li>A la hora de seleccionar una m\u00e9trica, \u00e9sta debe mostrar un valor que se vaya modificando seg\u00fan la utilizaci\u00f3n a nivel de ASG.</li> <li>Por ejemplo, usar la m\u00e9trica <code>RequestCount</code> del ELB no sirve porque el valor no tiene nada que ver con el ASG. Es decir, por m\u00e1s recursos que tenga nuestro ASG esa m\u00e9trica no se ver\u00e1 afectada.</li> <li>Es posible usar <code>metric math</code> para consultar m\u00faltiples m\u00e9tricas y mediante expresiones matem\u00e1ticas crear nuevos <code>time series</code>. Aqu\u00ed se explica con m\u00e1s detalle.</li> </ul> </li> <li>Step scaling<ul> <li>Aumenta o disminuye la capacidad actual en funci\u00f3n de una serie de ajustes de escalado.</li> <li>Varian en funci\u00f3n del tama\u00f1o de la interrupci\u00f3n de la alarma.</li> <li>Por ejemplo, si la alerta est\u00e1 al 60%, se escalan 10, al 70% 20 y al 80% 30 instancias.</li> <li>Desde la consola el valor es absoluto mientras que desde la CLI o SDK es relativo.</li> <li>Hay que evitar que el valor de las m\u00e9tricas se solapen.</li> <li>Hay varios tipos de ajustes a definir para optimizar el escalado (tambi\u00e9n v\u00e1lidos para simple scaling):</li> <li>ChangeInCapacity<ul> <li>Incrementa o reduce el capacity seg\u00fan un valor espec\u00edfico.</li> <li>Hab\u00eda 3 instancia, salta la alerta, la cual define 5 instancias, el valor del capacity ser\u00e1 8.</li> </ul> </li> <li>ExactCapacity<ul> <li>Cambia el capacity a un valor concreto.</li> <li>Hab\u00eda 3 instancia, salta la alerta, la cual define 5 instancias, el valor del capacity ser\u00e1 5.</li> </ul> </li> <li>PercentChangeInCapacity<ul> <li>Incrementa o reduce el capacity seg\u00fan un porcentaje.</li> <li>Es posible indicar un m\u00ednimo de instancias a escalar.</li> </ul> </li> </ul> </li> <li>Simple scaling<ul> <li>Es igual que step scaling a exepci\u00f3n de que el estado <code>in-progress</code> o los health checks debe de completarse y que adem\u00e1s, debe completarse el <code>cooldown period</code> antes de que responda a m\u00e1s alertas.</li> <li>Se recomienda usar step scaling, dado que es un tipo de pol\u00edtica m\u00e1s moderna.</li> </ul> </li> </ul> </li> </ul>"},{"location":"aws/asg/#use-predictive-scaling","title":"Use predictive scaling","text":"<ul> <li>ASG es trata de predecir cuando debe escalar.</li> <li>Se basa en anteriores acciones para realizar la predicci\u00f3n.</li> <li>Es posible combinarlo con el tipo scale based on demand.</li> </ul>"},{"location":"aws/lambda/","title":"AWS - Lambda","text":"<p>Es un servicio serverless de computaci\u00f3n, permite subir el c\u00f3digo de la aplicaci\u00f3n mediante funciones y luego invocarlas.</p>"},{"location":"aws/lambda/#caracteristicas-principales","title":"Caracter\u00edsticas principales","text":"<ul> <li>Servicio serverless.</li> <li>AWS se encarga de gestionar los servidores que necesita la aplicaci\u00f3n para funcionar.</li> <li>Es posible invocar manualmente una funci\u00f3n desde:         * Consola, petici\u00f3n HTTP, AWS CLI o AWS CDK.</li> <li>Las funciones pueden ser disparadas por otros servicios de AWS mediante eventos (JSON). Algunos de los servicios con los que se puede integrar son:         * Amazon S3         * Amazon SNS         * Amazon API Gateway</li> <li>Los servicios Amazon SQS y Amazon Kineses no puede disparar directamente una funci\u00f3n, sino que se usa la funcionalidad event source mapping.</li> <li>La funci\u00f3n est\u00e1 compuesta por:         * Lenguaje de programaci\u00f3n y su versi\u00f3n.         * Arquitectura.         * CPU, RAM y almacenamiento ef\u00edmero.</li> <li>Cuando una funci\u00f3n es invocada, el entorno creado se queda congelador por unas horas por si hubiera que gestionar m\u00e1s eventos.</li> <li>Si una funci\u00f3n requiere de librer\u00edas externas, \u00e9stas deber\u00e1n de incluirse junto al c\u00f3digo, habiendo distintas formas:<ol> <li>Archivo zip.</li> <li>Lambda Layers.</li> <li>Contenedor de Docker.</li> </ol> </li> <li>Podemos usar las funcionalidades alias y version para invocar una versi\u00f3n de la funci\u00f3n inmutable.</li> <li>Podemos verificar que el c\u00f3digo ejecutado est\u00e1 correctamente firmado por una fuente confiable usando la funcionalidad code signing.</li> <li>Una funci\u00f3n puede invocarse de forma s\u00edncrona o as\u00edncrona.</li> <li>Es posible crear una URL p\u00fablica para invocar a la funci\u00f3n.</li> <li>El servicio dispone de una quota que limite el n\u00famero de invocaciones simult\u00e1neas (concurrency).</li> <li>Mediante reserved concurrency podemos establecer l\u00edmites a las invocaciones simult\u00e1neas de las funciones.</li> <li>Mediante provisioned concurreny podemos tener entornos de ejecuci\u00f3n listos para responder a las invocaciones.</li> <li>El servicio Application Auto Scaling nos permite escalar bajo demanda o programado el incremento de entornos de ejecuci\u00f3n.</li> <li>Usando Lambda SnapStart podemos incrementar los tiempos de respuesta y escalado.</li> <li>Podemos usar hooks cuando usamos Lambda SnapStart.</li> <li>Mediante el servicio Amazon Application Auto Scaling podemos configurar unas reglas para que el runtime de la funci\u00f3n escale autom\u00e1ticamente seg\u00fan la carga.</li> <li>Podemos monitorizar las funciones con los servicios:         * CloudWatch metrics.         * CloudWatch Logs.         * AWS X-Ray.</li> <li>Tiene un escalado 'scale-out' autom\u00e1tico.</li> <li>Cada funci\u00f3n es independiente (1 evento = 1 funci\u00f3n).</li> <li>Un evento puede ejecutar X funciones de Lamba.</li> <li>Una funci\u00f3n Lambda puede llamar a otra funci\u00f3n Lambda.</li> <li>Lamba realiza las acciones de forma global (no depende de regiones o AZs).</li> <li>Hay unos pocos servicios los que pueden interactuar con Lamba.</li> </ul>"},{"location":"aws/lambda/#consideraciones","title":"Consideraciones","text":"<ol> <li>Cuidado con crear bucles infinitos (lambda -&gt; S3 -&gt; Lambda -&gt; S3)</li> <li>Ser precisos con las dependencias que requiere la funci\u00f3n (cargar un m\u00e9todo en lugar de toda la librer\u00eda).</li> <li>Dise\u00f1ar con detalle la fase de inicializaci\u00f3n de la funci\u00f3n, dado que el entorno se reusa aproximadamente durante 5 horas.</li> <li>No usar global variables dado que si el entorno no fue eliminado por AWS, no volver\u00e1n a inicializarse.</li> <li>Usar Secrets Manager o Parameter Store para evitar nuevos despliegues en cambio de datos poco frecuentes.</li> <li>Funciones sencillas, concretas y agn\u00f3sticas.</li> <li>Usar DynamoDB TTL para evitar que un evento se procese m\u00faltiples veces, es decir, que \u00e9ste sea idempotente.</li> <li>Analizar el sentido de la implementaci\u00f3n de la funci\u00f3n, quiz\u00e1s tenga m\u00e1s sentido que sea S3 quien haga la invocaci\u00f3n en lugar de que sea Lambda.</li> <li>Evitar tareas as\u00edncronas, es decir, que requieran llamar a otros componentes para poder terminar su procesamiento, el motivo son costes, tiempo de ejecuci\u00f3n, gesti\u00f3n de errores y escalado.         * Usar Amazon SQS suele ser una opci\u00f3n recomendable.</li> </ol>"},{"location":"aws/lambda/#detalle","title":"Detalle","text":"<ul> <li>Servicio serverless.</li> <li>AWS se encarga de gestionar los servidores que necesita la aplicaci\u00f3n para funcionar.</li> <li>Una funci\u00f3n Lambda se puede invokar manualmente v\u00eda:<ul> <li>Consola, petici\u00f3n HTTP, AWS CLI o AWS CDK.</li> </ul> </li> <li>Tambi\u00e9n mediante un evento espec\u00edfico, al cual se le ha asociado un trigger de Lambda, la cual ser\u00e1 invocada por el servicio de AWS, convirti\u00e9ndolo en un objeto JSON llamado <code>event</code>.</li> <li>Algunos otros servicios de AWS como Amazon Kinesis o Amazon SQS no pueden invocar a Lambda directamente, por lo que es necesario crear un <code>event source mapping</code>. Dicho evento hace que la funci\u00f3n Lambda est\u00e1 continuamente haciendo 'polls' de los servicios mencionados para verificar si hay nuevos eventos a gestionar</li> <li>Algunos servicios de AWS invocan directamente una funci\u00f3n Lambda usando <code>triggers</code>.<ul> <li>Estos servicios hacer un event push a Lambda, la cual invoca la funci\u00f3n inmediatamente cuando el evento ocurre.</li> <li>Este modo es apropiado para proceso en tiempo real o eventos discretos/aislados.</li> <li>Algunos servicios que usan triggers para invocar a las funciones:<ul> <li>S3 (cuando un objeto es creado, eliminado o modificado en un bucket).</li> <li>SNS (cuando un mensaje es publicado en un topic).</li> <li>API Gateway (cuando una request es realizada a un endpoint concreto).</li> </ul> </li> </ul> </li> <li>Es posible usar la herramienta AWS Lambda Power Tuning para medir el rendimiento de la funci\u00f3n mediante distintos valores de la RAM.</li> <li>Al incrementar la RAM de la funci\u00f3n, tambi\u00e9n se obtiene m\u00e1s CPU.</li> <li>El entorno de ejecuci\u00f3n tiene un almacenamiento ef\u00edmero en <code>/tmp/</code>, el cual perdura mientras el entorno est\u00e9 levantado.<ul> <li>El m\u00ednimo son 512MB pero puede incrementarse hasta 10GB.</li> <li>Toda la informaci\u00f3n almacena es cifrada en rest.</li> </ul> </li> <li>Es posible conectar funciones Lambda a VPC de modo que \u00e9stas pueden usar servicios alojados en redes privadas.</li> <li>Es posible invocar una funci\u00f3n Lambda desde un recurso de AWS a trav\u00e9s de AWS PrivateLink sin necesidad de ir por redes p\u00fablicas - Internet -.</li> <li>Podemos montar sistemas de archivos Amazon EFS en nuestras funciones Lambda.</li> <li>Podemos obtener informaci\u00f3n din\u00e1micamente usando de varias maneras:<ul> <li>Variables de entorno: Se configurar\u00e1n en la propia funci\u00f3n.</li> <li>Secrets Manager: Se obtienen los valores realizando llamadas a la API.</li> <li>Parameter Store: Se obtienen los valores realizando llamadas a la API.</li> </ul> </li> <li>El coste que tiene Lamba se basa en 2 partes:<ul> <li>N\u00famero de peticiones:<ul> <li>El primer mill\u00f3n son gratuitas.</li> </ul> </li> <li>Duraci\u00f3n de la funci\u00f3n:<ul> <li>Tiempo que dura la funci\u00f3n y la RAM asignada a dicha funci\u00f3n.</li> </ul> </li> </ul> </li> </ul>"},{"location":"aws/lambda/#event-source-mapping","title":"Event source mapping","text":"<ul> <li>Es un recurso de Lambda que leer desde un stream o un servicio de solas e invoca una funci\u00f3n con un lote de registros.</li> <li>Los recursos se llaman event pollers, es decir que activamente est\u00e1n haciendo poll en busca de nuevos mensajes, los cuales acaban invocando la funci\u00f3n Lambda.</li> <li>Los eventos se ejecutan al menos una vez, aunque es posible que se hagan m\u00e1s de una vez, por lo que es importante hacer las funciones idempotentes.</li> <li>Est\u00e1 dise\u00f1ado para el procesamiento de una gran volumen de streaming data o mensajes de colas.</li> <li>Por defecto, se agrupan los registros en un simple payload, el cual es enviado a la funci\u00f3n.</li> <li>Los condiciones para que se ejecute el batching:</li> <li>Por tiempo.</li> <li>Por tama\u00f1o del batch,</li> <li>Por tama\u00f1o en bytes de los batches.</li> <li>TODO https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html</li> </ul>"},{"location":"aws/lambda/#permisos","title":"Permisos","text":"<p>Hay dos tipos de permisos para las funciones: * El que necesita la funci\u00f3n para acceder a otros recursos de AWS (<code>execution role</code>).     * Al crear una funci\u00f3n, autom\u00e1ticamente se crea un rol con permisos de escritura en Amazon CloudWatch Logs. * El que necesitan otros recursos o usuarios para invocar a la funci\u00f3n.     * El permiso de otros servicios servicios para usar la funci\u00f3n es <code>lambda:InvokeFunction</code>.</p> <ul> <li>Una funci\u00f3n tiene acceso al directorio <code>/tmp/</code>.</li> </ul>"},{"location":"aws/lambda/#lifecycle","title":"Lifecycle","text":"<p>Las fases que conforman el <code>Lambda execution environment lifecycle</code> son:</p> <ol> <li><code>Init</code>.<ul> <li>Realiza 3 tareas en 10 segundos (iniciar las extensiones, iniciar el runtime y cargar la funci\u00f3n).</li> <li>Adicionalmente, puede ejecutar un hook <code>before-checkpoint</code> mediante Lambda SnapStart.</li> </ul> </li> <li><code>Invoke</code>.<ul> <li>Aqu\u00ed es cuando se ejecuta el c\u00f3digo.</li> <li>Se dispone de un timeout m\u00e1ximo de 360 segundos para que nuestra ejecuci\u00f3n termine.</li> <li>La duraci\u00f3n reportada es la suma de la fase de init y el tiempo que tard\u00f3 la funci\u00f3n en concluir.</li> <li>Si la funci\u00f3n falla u obtiene un timeout, el entorno de ejecuci\u00f3n es reiniciado.</li> </ul> </li> <li>Cuando una funci\u00f3n fue invocada, Lambda mantiene el entorno de ejecuci\u00f3n activo (queda congelado) por unas horas por si se hubiera otro evento que gestionar.<ul> <li>Tambi\u00e9n afecta a invocaciones de tipo continuously.</li> <li>Las declaraciones fuera del m\u00e9todo <code>handle</code> persisten, por ejemplo, la conexi\u00f3n establecida por una DB - es recomendable revisar si ya conexi\u00f3n ya existe antes de crear una nueva -.</li> <li>Los datos cacheados almacenados en <code>/tmp/</code> persisten, por lo que es recomendable analizar si son v\u00e1lidos para las siguientes ejecuciones.</li> <li>Hay que asegurar de no dejar procesos en segundo plano o callbacks comprobando esto mismo antes de arrojar un exit en el c\u00f3digo.</li> </ul> </li> <li>Hay dos tipos de 'starts' :<ul> <li>Cold: No hay entorno de ejecuci\u00f3n activo, por lo que Lambda debe descargar el c\u00f3digo e inicializar el entorno antes de inicializar el c\u00f3digo y ejecutar el handle.<ul> <li>Este tipo de 'start' provoca una mayor latencia (100ms a 1s).</li> </ul> </li> <li>Warn: Cuando el entorno de ejecuci\u00f3n est\u00e1 activo - congelado -, dado que no hay que inicializar el entorno.</li> </ul> </li> <li>Antes de ejecutar el c\u00f3digo del handle, Lambda hace una 'static initialization' del c\u00f3digo, es decir, importa las dependencias y librer\u00edas, establece la configuraci\u00f3n e inicializa la conexi\u00f3n con otros servicios (el c\u00f3digo ejecutado antes de llamar a la funci\u00f3n <code>lambda_handler</code>).<ul> <li>Si el entorno de ejecuci\u00f3n sigue activo, no vuelve a inicializarse de nuevo.</li> <li>Hay que tratar de ser precisos a la hora de realizar las llamadas a los servicios (en lugar de usar <code>aws-sdk</code> usar <code>aws-sdk/clients/dynamodb</code>).</li> <li>Suele ser recomendable iniciar las conexiones a la DB para as\u00ed ser reutilizadas en posteriores invocaciones.</li> <li>Usar <code>variable scope</code> en lugar de <code>global variables</code>, dado que si el entorno se mantiene, est\u00e1s continuar\u00e1n teniendo su valor.</li> </ul> </li> </ol>"},{"location":"aws/lambda/#lambda-runtime","title":"Lambda Runtime","text":"<ul> <li>Lambda soporte una serie de lenguajes de programaci\u00f3n como Python o NodeJS, aqu\u00ed el detalle completo.</li> <li>Es posible usar OS-only runtime para usar otros lenguajes de programaci\u00f3n.</li> <li>Cada major release tiene su runtime concreto, por ejemplo; Python 3.13.</li> <li>Para que una funci\u00f3n use una versi\u00f3n de runtime superior, habr\u00e1 que cambiar el runtime identifier.</li> <li>Para funciones definidas como contenedores, es necesario crear una nueva imagen.</li> <li>Si se us\u00f3 un archivo .zip para desplegar un paquete, es necesario actualizar la configuraci\u00f3n de la funci\u00f3n.</li> <li>Un runtime tiene su ciclo de vida:<ul> <li>Release -&gt; Deprecated date -&gt; Block function create (30 d\u00edas tras el deprecated date) -&gt; Block function update (60 d\u00edas tras el deprecated date).</li> </ul> </li> <li>La pol\u00edtica de deprecated runtime se produce cuando el runtime lleva al final de su LTS y ya no recibe actualizaciones de seguridad.</li> <li>Mediante Lambda versions y aliases es posible realizar la migraci\u00f3n a una versi\u00f3n superior del runtime.</li> <li>Es posible seguir usando funciones que se ejecutan sobre runtimes deprecated, no obstante, \u00e9stas son vulnerables a nivel de bugs, seguridad y rendimiento.</li> <li>Se reciben notificaciones advirtiendo que nuestro runtime en uso quedar\u00e1 deprecated en 180 d\u00edas.</li> <li>Por defecto para los runtimes gestionados, Lambda aplica las actualizaciones autom\u00e1ticamente, aunque es posible indicar que s\u00f3lo se actualice el runtime cuando la funci\u00f3n sea actualizada o manualmente, indicando el ARN del runtime.</li> </ul>"},{"location":"aws/lambda/#alias-y-versions","title":"Alias y Versions","text":"<p>Alias</p> <ul> <li>Referencia a una versi\u00f3n concreta de una funci\u00f3n.</li> <li>Es posible actualizar el alias.</li> <li>Es posible desplegar nuevas versiones mediante un Canary Deployment.</li> </ul> <p>Versions</p> <ul> <li>La \u00faltima versi\u00f3n de la funci\u00f3n sin publicar se denomina <code>$LATEST</code>.</li> <li>Cada vez que se publica una nueva versi\u00f3n de la funci\u00f3n se sobreescribe el c\u00f3digo de <code>$LATEST</code>.</li> <li><code>$LATEST</code> es mutable, es decir, podemos modificarla.</li> <li>Cuando una versi\u00f3n es publicada, se convierte en inmutable.</li> <li>Es posible referenciar una funci\u00f3n usando Qualified o Unqualified ARN.<ul> <li>Qualified: Referencia a una versi\u00f3n de la funci\u00f3n.</li> <li>Unqualified: No referencia ninguna versi\u00f3n. Adem\u00e1s, no es posible usar un alias con este tipo.</li> </ul> </li> </ul>"},{"location":"aws/lambda/#lambda-layers","title":"Lambda layers","text":"<ul> <li>https://docs.aws.amazon.com/lambda/latest/dg/chapter-layers.html</li> <li>Es un archivo .zip que contiene c\u00f3digo o datos adicionales.</li> <li>Generalmente contienen dependencias de librer\u00edas, archivos de configuraci\u00f3n o custom runtimes.</li> <li>Es posible usar la misma layer en m\u00faltiples funciones.</li> <li>El contenido de la layer se extrae en el directorio <code>/opt/</code> del entorno de ejecuci\u00f3n.</li> <li>No es posible usar esta funcionalidad con funciones Dockerizadas.</li> <li>Una layer version es una snapshot inmutable de una versi\u00f3n concreta. Cuando creamos una layer, Lambda crea su versi\u00f3n concreta.</li> <li>Es posible vincular un m\u00e1ximo de 5 layers en una funci\u00f3n.</li> <li>La funci\u00f3n debe ser compatible con el runtime y la arquitectura.</li> <li>El tama\u00f1o total de las layers no puede superar los 250MB.</li> </ul>"},{"location":"aws/lambda/#code-signing","title":"Code signing","text":"<ul> <li>Permite verificar que el c\u00f3digo ejecutado est\u00e1 correctamente firmado por una fuente confiable.</li> <li>Lambda comprueba y verifica el c\u00f3digo de cada deployment.</li> <li>No est\u00e1 disponible para funciones desplegadas con im\u00e1genes Docker.</li> <li>A trav\u00e9s de AWS Signer se gestiona las firmas de los paquetes de las funciones y sus layers.<ul> <li>Servicio sin costes.</li> </ul> </li> <li>Es necesario subir la funci\u00f3n Lambda como .zip en un bucket de S3, dado que AWS Signed firmar\u00e1 dicho archivo y generar\u00e1 uno nuevo, siendo \u00e9ste el usado por nuestra funci\u00f3n.</li> <li>En AWS CloudTrail se registran los deployments exitosos o fallidos.</li> <li>Amazon Lambda realiza las siguientes pruebas de validaci\u00f3n cuando desplegamos un cambio en nuestra funci\u00f3n firmada:<ul> <li>Integrity: Valida que el paquete no ha sido modificado desde que fue firmado (revisa el hash).</li> <li>Expiry: Valida que la firma no ha expirado.</li> <li>Mismatch: Valida que la firma se haya hecho con un perfil permitido.</li> <li>Revocation: Valida que la firma no haya sido revocada.</li> </ul> </li> <li>Cuando una validaci\u00f3n falla, podemos tomar dos acciones:<ul> <li>Warn: Advierte en CloudWatch y CloudTrail aunque la funci\u00f3n es ejecutada.</li> <li>Enforce: Advierte y bloquea la ejecuci\u00f3n.</li> </ul> </li> </ul>"},{"location":"aws/lambda/#tipos-de-invocaciones","title":"Tipos de invocaciones","text":"<p>Synchronous invocations</p> <ul> <li>Esperamos a que la funci\u00f3n procese el evento y devuelva una respuesta.</li> <li>En caso de error, se muestra el mensaje en la respuesta y los retries deber\u00e1n de ser manuales.</li> <li>La respuesta contiene informaci\u00f3n adicional como la versi\u00f3n de la funci\u00f3n ejecutada.</li> </ul> <p>Asynchronous invocations</p> <ul> <li>Se env\u00eda el evento a Lambda, el cual es encolado y proceso posteriormente. Lambda nos devuelve inmediatamente un simple HTTP 202.</li> <li>Para que la invocaci\u00f3n sea de este tipo, es necesario settear el par\u00e1metro <code>InvocationType</code> con valor <code>Event</code>.</li> <li>En caso de error, Lambda hace los retries autom\u00e1ticamente.<ul> <li>Por defecto, lo intento dos veces m\u00e1s, con ciertos minutos de margen entre los intentos.</li> </ul> </li> <li>Podemos configurar la gesti\u00f3n de errores.<ul> <li>Tiempo m\u00e1ximo en segundos en los que un evento est\u00e1 encolado antes de descartarse.</li> <li>N\u00famero m\u00e1ximo de intentos.</li> </ul> </li> <li>Es posible enviar registros de la invocaci\u00f3n a ciertos servicios de AWS (destinations), estos registros contienen informaci\u00f3n adicional de la requests as\u00ed como su response.<ul> <li>Es posible establecer distintos destinations seg\u00fan si el procesamiento fue exitoso o fallido.</li> <li>Podemos configurar una dead-letter queue (SQS o SNS) para enviar los eventos descartados, estos tendr\u00e1n el contenido del evento pero no los detalles de la respuesta.</li> <li>Como alternativa tenemos dead letter queues.</li> </ul> </li> </ul>"},{"location":"aws/lambda/#concurrency","title":"Concurrency","text":"<ul> <li>https://docs.aws.amazon.com/lambda/latest/dg/lambda-concurrency.html</li> <li>N\u00famero de requests in-flight que la funci\u00f3n Lambda gestiona al mismo tiempo.</li> <li>Cada execution environment puede gestionar una \u00fanica request (concurrency 1). Cuando la invocaci\u00f3n termina, dicho entorno se reusa para gestionar una nueva petici\u00f3n.</li> <li>Cuando se reciben m\u00faltiples requests al mismo tiempo, se van creando nuevos execution enviroments.</li> <li>Lambda tiene una quota por defecto de 1.000 execution environments por regi\u00f3n, es decir, que se pueden gestionar 1.000 invocaciones (concurrency 1.000) simult\u00e1neas.</li> <li>Aqu\u00ed se muestra una f\u00f3rmula para calcular el concurrency de una funci\u00f3n Lambda.</li> <li>Cuando se llega al l\u00edmite de la quota de concurrency, la funci\u00f3n experimenta throttling, es decir, se rechazan las requests (429 status code).</li> <li>Hay dos tipos de concurrency:<ul> <li>Reserved<ul> <li>Reserva un n\u00famero de concurrency para una funci\u00f3n concreta, de modo que se evita que otra funci\u00f3n acapare la creaci\u00f3n de execution environments. Dicho de otro modo, es el n\u00famero m\u00e1ximo de execution environments que puede usar una funci\u00f3n.</li> <li>No hay costes adicionales por usar esta configuraci\u00f3n.</li> </ul> </li> <li>Provisioned<ul> <li>Pre-inicializa un n\u00famero concreto de execution environments para una funci\u00f3n.</li> <li>Reduce la latencia del cold start.</li> <li>El uso de esta funcionalidad tiene coste adicional.</li> <li>A excepci\u00f3n de Java 11 o 17, no es posible usar la funcionalidad Lambda SnapStart junto con Provisioned concurrency.</li> <li>Es posible usar Reserved concurrency tambi\u00e9n.</li> <li>No es posible tener m\u00e1s provisioned que Reserved concurrency.</li> <li>S\u00f3lo puede aplicarse a nivel de alias o versi\u00f3n.</li> <li>Es posible usa el servicio Application Auto Scaling.</li> <li>Hay dos maneras de configurar el servicio:<ul> <li>Schedule scaling<ul> <li>Para tr\u00e1fico predecible.</li> <li>Es posible configurar en base a una m\u00e9trica de CloudWatch o a un fecha y hora concreta.</li> <li>Art\u00edculo donde se realiza la implementaci\u00f3n.</li> <li>Doc donde explica la funcionalidad a implementar.</li> </ul> </li> <li>Target tracking<ul> <li>Cuando no hya patrones de tr\u00e1fico predecibles.</li> <li>Crea y gestiona una serie de alertas en CloudWatch basadas en la pol\u00edtica definida.</li> <li>Cuando la alertas se activa, se Application Auto Scaling ajusta autom\u00e1ticamente el valor de provisioned concurrency.</li> <li>Breve explicaci\u00f3n de como implementarlo.</li> <li>Doc donde explica la funcionalidad a implementar.</li> </ul> </li> </ul> </li> <li>Se requiere definir un valor inicial en el provisioned concurrency.</li> <li>Ambos modos de configuraci\u00f3n deber\u00e1n ser aplicados v\u00eda CLI, dado que la configuraci\u00f3n no est\u00e1 disponible v\u00eda consola.</li> </ul> </li> </ul> </li> </ul>"},{"location":"aws/lambda/#lambda-snapstart","title":"Lambda SnapStart","text":"<p>TODO https://docs.aws.amazon.com/lambda/latest/dg/snapstart.html</p> <ul> <li>La fase de Init sucede tras publicar una funci\u00f3n. Lambda hace una snapshot de la memoria y el estado del disco tras la iniciaci\u00f3n del entorno de ejecuci\u00f3n, la cifra y cachea.</li> <li>Si tenemos before-checkpoint runtime hook, el c\u00f3digo se ejecutar\u00e1 al final de la fase de Init.</li> <li><code>Hooks</code><ul> <li>https://docs.aws.amazon.com/lambda/latest/dg/snapstart-runtime-hooks.html</li> </ul> </li> </ul>"},{"location":"aws/lambda/#monitorizacion","title":"Monitorizaci\u00f3n","text":"<p>TODO https://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs.html</p> <p>X-ray</p> <ul> <li>Permite debugear lo que ocurre en una aplicaci\u00f3n serverless.</li> </ul>"}]}